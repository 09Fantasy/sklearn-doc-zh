# 2. 无监督学习
* [2.1 高斯混合模型](docs/20.md?id=_21-高斯混合模型)
    * [2.1.1 高斯混合](docs/20.md?id=_211-高斯混合)
        * [2.1.1.1 优缺点](docs/20.md?id=_2111-优缺点-gaussianmixture)
            * [2.1.1.1.1 优点](docs/20.md?id=_21111-优点)
            * [2.1.1.1.2 缺点](docs/20.md?id=_21112-缺点)
        * [2.1.1.2 选择经典高斯混合模型中分量的个数](docs/20.md?id=_2112-选择经典高斯混合模型中分量的个数)
        * [2.1.1.3 估计算法期望最大化（EM）](docs/20.md?id=_2113-估计算法期望最大化（em）)
    * [2.1.2 变分贝叶斯高斯混合](docs/20.md?id=_212-变分贝叶斯高斯混合)
        * [2.1.2.1 估计算法: 变分推断（variational inference）](docs/20.md?id=_2121-估计算法:-变分推断（variational-inference）)
            * [2.1.2.2. BayesianGaussianMixture下的变分推理的优缺点](docs/20.md?id=_2122-bayesiangaussianmixture-下的变分推理的优缺点)
            * [2.1.2.2.1 优点](docs/20.md?id=_21221-优点)
            * [2.1.2.2.2 缺点](docs/20.md?id=_21222-缺点)
        * [2.1.2.3 The Dirichlet Process（狄利克雷过程）](docs/20.md?id=_2123-the-dirichlet-process（狄利克雷过程）)
* [2.2 流形学习](docs/21.md?id=_22-流形学习)
    * [2.2.1 介绍](docs/21.md?id=_221-介绍)
    * [2.2.2 Isomap](docs/21.md?id=_222-isomap)
        * [2.2.2.1 复杂度](docs/21.md?id=_2221-复杂度)
    * [2.2.3 局部线性嵌入](docs/21.md?id=_223-局部线性嵌入)
        * [2.2.3.1 复杂度](docs/21.md?id=_2231-复杂度)
    * [2.2.4 改进型局部线性嵌入（MLLE）](docs/21.md?id=_224-改进型局部线性嵌入（mlle）)
        * [2.2.4.1 复杂度](docs/21.md?id=_2241-复杂度)
    * [2.2.5 黑塞特征映射（HE）](docs/21.md?id=_225-黑塞特征映射（he）)
        * [2.2.5.1 复杂度](docs/21.md?id=_2251-复杂度)
    * [2.2.6 谱嵌入](docs/21.md?id=_226-谱嵌入)
        * [2.2.6.1 复杂度](docs/21.md?id=_2261-复杂度)
    * [2.2.7 局部切空间对齐（LTSA）](docs/21.md?id=_227-局部切空间对齐（ltsa）)
        * [2.2.7.1 复杂度](docs/21.md?id=_2271-复杂度)
    * [2.2.8 多维尺度分析（MDS）](docs/21.md?id=_228-多维尺度分析（mds）)
        * [2.2.8.1 度量 MDS](docs/21.md?id=_2281-度量-mds)
        * [2.2.8.2 非度量 MDS](docs/21.md?id=_2282-非度量-mds)
    * [2.2.9 t 分布随机邻域嵌入（t-SNE）](docs/21.md?id=_229-t-分布随机邻域嵌入（t-sne）)
        * [2.2.9.1 优化 t-SNE](docs/21.md?id=_2291-优化-t-sne)
        * [2.2.9.2 Barnes-Hut t-SNE](docs/21.md?id=_2292-barnes-hut-t-sne)
    * [2.2.10 实用技巧](docs/21.md?id=_2210-实用技巧)
* [2.3 聚类](docs/22.md?id=_23-聚类)
    * [2.3.1 聚类方法概述](docs/22.md?id=_231-聚类方法概述)
    * [2.3.2 K-means](docs/22.md?id=_232-k-means)
        * [2.3.2.1 小批量 K-Means](docs/22.md?id=_2321-小批量-k-means)
    * [2.3.3 Affinity Propagation](docs/22.md?id=_233-affinity-propagation)
    * [2.3.4 Mean Shift](docs/22.md?id=_234-mean-shift)
    * [2.3.5 Spectral clustering](docs/22.md?id=_235-spectral-clustering)
        * [2.3.5.1 不同的标记分配策略](docs/22.md?id=_2351-不同的标记分配策略)
        * [2.3.5.2 谱聚类用于图聚类问题](docs/22.md?id=_2352-谱聚类用于图聚类问题)
    * [2.3.6 层次聚类](docs/22.md?id=_236-层次聚类)
        * [2.3.6.1 不同连接类型: Ward, complete and average linkage](docs/22.md?id=_2361-不同连接类型:-ward,-complete-and-average-linkage)
        * [2.3.6.2 添加连接约束](docs/22.md?id=_2362-添加连接约束)
        * [2.3.6.3 Varying the metric](docs/22.md?id=_2363-varying-the-metric)
    * [2.3.7 DBSCAN](docs/22.md?id=_237-dbscan)
    * [2.3.8 OPTICS](docs/22.md?id=_238-optics)
    * [2.3.9 Birch](docs/22.md?id=_239-birch)
    * [2.3.10 聚类性能度量](docs/22.md?id=_2310-聚类性能度量)
        * [2.3.10.1 调整后的 Rand 指数](docs/22.md?id=_23101-调整后的-rand-指数)
            * [2.3.10.1.1 优点](docs/22.md?id=_231011-优点)
            * [2.3.10.1.2 缺点](docs/22.md?id=_231012-缺点)
            * [2.3.10.1.3 数学表达](docs/22.md?id=_231013-数学表达)
        * [2.3.10.2 基于 Mutual Information （互信息）的分数](docs/22.md?id=_23102-基于-mutual-information-（互信息）的分数)
            * [2.3.10.2.1 优点](docs/22.md?id=_231021-优点)
            * [2.3.10.2.2 缺点](docs/22.md?id=_231022-缺点)
            * [2.3.10.2.3 数学公式](docs/22.md?id=_231023-数学公式)
        * [2.3.10.3 同质性，完整性和 V-measure](docs/22.md?id=_23103-同质性，完整性和-v-measure)
            * [2.3.10.3.1 优点](docs/22.md?id=_231031-优点)
            * [2.3.10.3.2 缺点](docs/22.md?id=_231032-缺点)
            * [2.3.10.3.3 数学表达](docs/22.md?id=_231033-数学表达)
        * [2.3.10.4 Fowlkes-Mallows 分数](docs/22.md?id=_23104-fowlkes-mallows-分数)
            * [2.3.10.4.1 优点](docs/22.md?id=_231041-优点)
            * [2.3.10.4.2 缺点](docs/22.md?id=_231042-缺点)
        * [2.3.10.5 Silhouette 系数](docs/22.md?id=_23105-silhouette-系数)
            * [2.3.10.5.1 优点](docs/22.md?id=_231051-优点)
            * [2.3.10.5.2 缺点](docs/22.md?id=_231052-缺点)
        * [2.3.10.6 Calinski-Harabaz 指数](docs/22.md?id=_23106-calinski-harabaz-指数)
            * [2.3.10.6.1 优点](docs/22.md?id=_231061-优点)
            * [2.3.10.6.2 缺点](docs/22.md?id=_231062-缺点)
* [2.4 双聚类](docs/23.md?id=_24-双聚类)
    * [2.4.1 Spectral Co-Clustering](docs/23.md?id=_241-spectral-co-clustering)
        * [2.4.1.1 数学公式](docs/23.md?id=_2411-数学公式)
    * [2.4.2 Spectral Biclustering](docs/23.md?id=_242-spectral-biclustering)
        * [2.4.2.1 数学表示](docs/23.md?id=_2421-数学表示)
    * [2.4.3 Biclustering 评价](docs/23.md?id=_243-biclustering-评价)
* [2.5 分解成分中的信号（矩阵分解问题）](docs/24.md?id=_25-分解成分中的信号（矩阵分解问题）)
    * [2.5.1 主成分分析（PCA）](docs/24.md?id=_251-主成分分析（pca）)
        * [2.5.1.1 准确的PCA和概率解释（Exact PCA and probabilistic interpretation）](docs/24.md?id=_2511-准确的pca和概率解释（exact-pca-and-probabilistic-interpretation）)
        * [2.5.1.2 增量PCA (Incremental PCA)](docs/24.md?id=_2512-增量pca-incremental-pca)
        * [2.5.1.3 PCA 使用随机SVD](docs/24.md?id=_2513-pca-使用随机svd)
        * [2.5.1.4 核 PCA](docs/24.md?id=_2514-核-pca)
        * [2.5.1.5 稀疏主成分分析 ( SparsePCA 和 MiniBatchSparsePCA )](docs/24.md?id=_2515-稀疏主成分分析--sparsepca-和-minibatchsparsepca-)
    * [2.5.2 截断奇异值分解和隐语义分析](docs/24.md?id=_252-截断奇异值分解和隐语义分析)
    * [2.5.3 词典学习](docs/24.md?id=_253-词典学习)
        * [2.5.3.1 带有预计算词典的稀疏编码](docs/24.md?id=_2531-带有预计算词典的稀疏编码)
        * [2.5.3.2 通用词典学习](docs/24.md?id=_2532-通用词典学习)
        * [2.5.3.3 小批量字典学习](docs/24.md?id=_2533-小批量字典学习)
    * [2.5.4 因子分析](docs/24.md?id=_254-因子分析)
    * [2.5.5 独立成分分析（ICA）](docs/24.md?id=_255-独立成分分析（ica）)
    * [2.5.6 非负矩阵分解(NMF 或 NNMF)](docs/24.md?id=_256-非负矩阵分解nmf-或-nnmf)
        * [2.5.6.1 NMF 与 Frobenius 范数](docs/24.md?id=_2561-nmf-与-frobenius-范数)
        * [2.5.6.2 具有 beta-divergence 的 NMF](docs/24.md?id=_2562-具有-beta-divergence-的-nmf)
    * [2.5.7 隐 Dirichlet 分配（LDA）](docs/24.md?id=_257-隐-dirichlet-分配（lda）)
* [2.6 协方差估计](docs/25.md?id=_26-协方差估计)
    * [2.6.1 经验协方差](docs/25.md?id=_261-经验协方差)
    * [2.6.2 收敛协方差](docs/25.md?id=_262-收敛协方差)
        * [2.6.2.1 基本收敛](docs/25.md?id=_2621-基本收敛)
        * [2.6.2.2 Ledoit-Wolf 收敛](docs/25.md?id=_2622-ledoit-wolf-收敛)
        * [2.6.2.3 Oracle 近似收缩](docs/25.md?id=_2623-oracle-近似收缩)
    * [2.6.3 稀疏逆协方差](docs/25.md?id=_263-稀疏逆协方差)
    * [2.6.4 Robust 协方差估计](docs/25.md?id=_264-robust-协方差估计)
        * [2.6.4.1 最小协方差决定](docs/25.md?id=_2641-最小协方差决定)
* [2.7 新奇和异常值检测](docs/26.md?id=_27-新奇和异常值检测)
    * [2.7.1 孤立点检测方法一览](docs/26.md?id=_271-孤立点检测方法一览)
    * [2.7.2 Novelty Detection（新奇检测）](docs/26.md?id=_272-novelty-detection（新奇检测）)
    * [2.7.3 Outlier Detection（异常值检测）](docs/26.md?id=_273-outlier-detection（异常值检测）)
        * [2.7.3.1 Fitting an elliptic envelope（椭圆模型拟合）](docs/26.md?id=_2731-fitting-an-elliptic-envelope（椭圆模型拟合）)
        * [2.7.3.2 Isolation Forest（隔离森林）](docs/26.md?id=_2732-isolation-forest（隔离森林）)
        * [2.7.3.3 Local Outlier Factor（局部异常系数）](docs/26.md?id=_2733-local-outlier-factor（局部异常系数）)
    * [2.7.4 使用LOF进行新奇点检测](docs/26.md?id=_274-使用lof进行新奇点检测)
* [2.8 密度估计](docs/27.md?id=_28-密度估计)
    * [2.8.1 密度估计: 直方图](docs/27.md?id=_281-密度估计:-直方图)
    * [2.8.2 核密度估计](docs/27.md?id=_282-核密度估计)
* [2.9 神经网络模型（无监督）](docs/28.md?id=_29-神经网络模型（无监督）)
    * [2.9.1 限制波尔兹曼机](docs/28.md?id=_291-限制波尔兹曼机)
        * [2.9.1.1 图形模型和参数化](docs/28.md?id=_2911-图形模型和参数化)
        * [2.9.1.2 伯努利限制玻尔兹曼机](docs/28.md?id=_2912-伯努利限制玻尔兹曼机)
        * [2.9.1.3 随机最大似然学习](docs/28.md?id=_2913-随机最大似然学习)
