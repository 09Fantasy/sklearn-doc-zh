# 1\. 监督学习

*   [1.1\. 广义线性模型](modules/linear_model.html)
    *   [1.1.1\. 普通最小二乘法](modules/linear_model.html#ordinary-least-squares)
        *   [1.1.1.1\. 普通最小二乘法复杂度](modules/linear_model.html#id3)
    *   [1.1.2\. 岭回归](modules/linear_model.html#ridge-regression)
        *   [1.1.2.1\. 岭回归的复杂度](modules/linear_model.html#id9)
        *   [1.1.2.2\. 设置正则化参数：广义交叉验证](modules/linear_model.html#id10)
    *   [1.1.3\. Lasso](modules/linear_model.html#lasso)
        *   [1.1.3.1\. 设置正则化参数](modules/linear_model.html#id12)
            *   [1.1.3.1.1\. 使用交叉验证](modules/linear_model.html#id13)
            *   [1.1.3.1.2\. 基于信息标准的模型选择](modules/linear_model.html#id14)
            *   [1.1.3.1.3\. 与 SVM 的正则化参数的比较](modules/linear_model.html#svm)
    *   [1.1.4\. 多任务 Lasso](modules/linear_model.html#id17)
    *   [1.1.5\. 弹性网络](modules/linear_model.html#elastic-net)
    *   [1.1.6\. 多任务弹性网络](modules/linear_model.html#multi-task-elastic-net)
    *   [1.1.7\. 最小角回归](modules/linear_model.html#least-angle-regression)
    *   [1.1.8\. LARS Lasso](modules/linear_model.html#lars-lasso)
        *   [1.1.8.1\. 数学表达式](modules/linear_model.html#id21)
    *   [1.1.9\. 正交匹配追踪法（OMP）](modules/linear_model.html#omp)
    *   [1.1.10\. 贝叶斯回归](modules/linear_model.html#bayesian-regression)
        *   [1.1.10.1\. 贝叶斯岭回归](modules/linear_model.html#bayesian-ridge-regression)
        *   [1.1.10.2\. 主动相关决策理论 - ARD](modules/linear_model.html#ard)
    *   [1.1.11\. logistic 回归](modules/linear_model.html#logistic)
    *   [1.1.12\. 随机梯度下降， SGD](modules/linear_model.html#sgd)
    *   [1.1.13\. Perceptron（感知器）](modules/linear_model.html#perceptron)
    *   [1.1.14\. Passive Aggressive Algorithms（被动攻击算法）](modules/linear_model.html#passive-aggressive-algorithms)
    *   [1.1.15\. 稳健回归（Robustness regression）: 处理离群点（outliers）和模型错误](modules/linear_model.html#robustness-regression-outliers)
        *   [1.1.15.1\. 各种使用场景与相关概念](modules/linear_model.html#id43)
        *   [1.1.15.2\. RANSAC： 随机抽样一致性算法（RANdom SAmple Consensus）](modules/linear_model.html#ransac-random-sample-consensus)
            *   [1.1.15.2.1\. 算法细节](modules/linear_model.html#id44)
        *   [1.1.15.3\. Theil-Sen 预估器: 广义中值估计器（generalized-median-based estimator）](modules/linear_model.html#theil-sen-generalized-median-based-estimator)
            *   [1.1.15.3.1\. 算法理论细节](modules/linear_model.html#id45)
        *   [1.1.15.4\. Huber 回归](modules/linear_model.html#huber)
        *   [1.1.15.5\. 注意](modules/linear_model.html#id48)
    *   [1.1.16\. 多项式回归：用基函数展开线性模型](modules/linear_model.html#polynomial-regression)
*   [1.2\. 线性和二次判别分析](modules/lda_qda.html)
    *   [1.2.1\. 使用线性判别分析来降维](modules/lda_qda.html#id2)
    *   [1.2.2\. LDA 和 QDA 分类器的数学公式](modules/lda_qda.html#id3)
    *   [1.2.3\. LDA 的降维数学公式](modules/lda_qda.html#lda)
    *   [1.2.4\. Shrinkage（收缩）](modules/lda_qda.html#shrinkage)
    *   [1.2.5\. 预估算法](modules/lda_qda.html#id6)
*   [1.3\. 内核岭回归](modules/kernel_ridge.html)
*   [1.4\. 支持向量机](modules/svm.html)
    *   [1.4.1\. 分类](modules/svm.html#svm-classification)
        *   [1.4.1.1\. 多元分类](modules/svm.html#svm-multi-class)
        *   [1.4.1.2\. 得分和概率](modules/svm.html#scores-probabilities)
        *   [1.4.1.3\. 非均衡问题](modules/svm.html#id5)
    *   [1.4.2\. 回归](modules/svm.html#svm-regression)
    *   [1.4.3\. 密度估计, 异常（novelty）检测](modules/svm.html#novelty)
    *   [1.4.4\. 复杂度](modules/svm.html#id7)
    *   [1.4.5\. 使用诀窍](modules/svm.html#id8)
    *   [1.4.6\. 核函数](modules/svm.html#svm-kernels)
        *   [1.4.6.1\. 自定义核](modules/svm.html#id10)
            *   [1.4.6.1.1\. 使用 python 函数作为内核](modules/svm.html#python)
            *   [1.4.6.1.2\. 使用 Gram 矩阵](modules/svm.html#gram)
            *   [1.4.6.1.3\. RBF 内核参数](modules/svm.html#rbf)
    *   [1.4.7\. 数学公式](modules/svm.html#svm-mathematical-formulation)
        *   [1.4.7.1\. SVC](modules/svm.html#svc)
        *   [1.4.7.2\. NuSVC](modules/svm.html#nusvc)
        *   [1.4.7.3\. SVR](modules/svm.html#svr)
    *   [1.4.8\. 实现细节](modules/svm.html#svm-implementation-details)
*   [1.5\. 随机梯度下降](modules/sgd.html)
    *   [1.5.1\. 分类](modules/sgd.html#id3)
    *   [1.5.2\. 回归](modules/sgd.html#id4)
    *   [1.5.3\. 稀疏数据的随机梯度下降](modules/sgd.html#id5)
    *   [1.5.4\. 复杂度](modules/sgd.html#id6)
    *   [1.5.5\. 实用小贴士](modules/sgd.html#id7)
    *   [1.5.6\. 数学描述](modules/sgd.html#sgd-mathematical-formulation)
        *   [1.5.6.1\. SGD](modules/sgd.html#id9)
    *   [1.5.7\. 实现细节](modules/sgd.html#id10)
*   [1.6\. 最近邻](modules/neighbors.html)
    *   [1.6.1\. 无监督最近邻](modules/neighbors.html#unsupervised-neighbors)
        *   [1.6.1.1\. 找到最近邻](modules/neighbors.html#id3)
        *   [1.6.1.2\. KDTree 和 BallTree 类](modules/neighbors.html#kdtree-balltree)
    *   [1.6.2\. 最近邻分类](modules/neighbors.html#classification)
    *   [1.6.3\. 最近邻回归](modules/neighbors.html#regression)
    *   [1.6.4\. 最近邻算法](modules/neighbors.html#id6)
        *   [1.6.4.1\. 暴力计算](modules/neighbors.html#brute-force)
        *   [1.6.4.2\. K-D 树](modules/neighbors.html#k-d)
        *   [1.6.4.3\. Ball 树](modules/neighbors.html#ball)
        *   [1.6.4.4\. 最近邻算法的选择](modules/neighbors.html#id8)
        *   [1.6.4.5\. `leaf_size` 的影响](modules/neighbors.html#leaf-size)
    *   [1.6.5\. 最近质心分类](modules/neighbors.html#nearest-centroid-classifier)
        *   [1.6.5.1\. 最近缩小质心](modules/neighbors.html#id10)
*   [1.7\. 高斯过程](modules/gaussian_process.html)
    *   [1.7.1\. 高斯过程回归（GPR）](modules/gaussian_process.html#gpr)
    *   [1.7.2\. GPR 示例](modules/gaussian_process.html#id4)
        *   [1.7.2.1\. 具有噪声级的 GPR 估计](modules/gaussian_process.html#id5)
        *   [1.7.2.2\. GPR 和内核岭回归(Kernel Ridge Regression)的比较](modules/gaussian_process.html#gpr-kernel-ridge-regression)
        *   [1.7.2.3\. Mauna Loa CO2 数据中的 GRR](modules/gaussian_process.html#mauna-loa-co2-grr)
    *   [1.7.3\. 高斯过程分类（GPC）](modules/gaussian_process.html#gpc)
    *   [1.7.4\. GPC 示例](modules/gaussian_process.html#id7)
        *   [1.7.4.1\. GPC 概率预测](modules/gaussian_process.html#id8)
        *   [1.7.4.2\. GPC 在 XOR 数据集上的举例说明](modules/gaussian_process.html#gpc-xor)
        *   [1.7.4.3\. iris 数据集上的高斯过程分类（GPC）](modules/gaussian_process.html#iris-gpc)
    *   [1.7.5\. 高斯过程内核](modules/gaussian_process.html#gp-kernels)
        *   [1.7.5.1\. 高斯过程内核 API](modules/gaussian_process.html#api)
        *   [1.7.5.2\. 基础内核](modules/gaussian_process.html#id11)
        *   [1.7.5.3\. 内核操作](modules/gaussian_process.html#id12)
        *   [1.7.5.4\. 径向基函数内核](modules/gaussian_process.html#id13)
        *   [1.7.5.5\. Matérn 内核](modules/gaussian_process.html#matern)
        *   [1.7.5.6\. 有理二次内核](modules/gaussian_process.html#id15)
        *   [1.7.5.7\. 正弦平方内核](modules/gaussian_process.html#id16)
        *   [1.7.5.8\. 点乘内核](modules/gaussian_process.html#id17)
        *   [1.7.5.9\. 参考文献](modules/gaussian_process.html#id18)
    *   [1.7.6\. 传统高斯过程](modules/gaussian_process.html#id19)
        *   [1.7.6.1\. 回归实例介绍](modules/gaussian_process.html#id20)
        *   [1.7.6.2\. 噪声数据拟合](modules/gaussian_process.html#id21)
        *   [1.7.6.3\. 数学形式](modules/gaussian_process.html#id22)
            *   [1.7.6.3.1\. 初始假设](modules/gaussian_process.html#id23)
            *   [1.7.6.3.2\. 最佳线性无偏预测（BLUP）](modules/gaussian_process.html#blup)
            *   [1.7.6.3.3\. 经验最佳线性无偏估计（EBLUP）](modules/gaussian_process.html#eblup)
        *   [1.7.6.4\. 关联模型](modules/gaussian_process.html#correlation-models)
        *   [1.7.6.5\. 回归模型](modules/gaussian_process.html#regression-models)
        *   [1.7.6.6\. 实现细节](modules/gaussian_process.html#id26)
*   [1.8\. 交叉分解](modules/cross_decomposition.html)
*   [1.9\. 朴素贝叶斯](modules/naive_bayes.html)
    *   [1.9.1\. 高斯朴素贝叶斯](modules/naive_bayes.html#gaussian-naive-bayes)
    *   [1.9.2\. 多项分布朴素贝叶斯](modules/naive_bayes.html#multinomial-naive-bayes)
    *   [1.9.3\. 伯努利朴素贝叶斯](modules/naive_bayes.html#bernoulli-naive-bayes)
    *   [1.9.4\. 堆外朴素贝叶斯模型拟合](modules/naive_bayes.html#id5)
*   [1.10\. 决策树](modules/tree.html)
    *   [1.10.1\. 分类](modules/tree.html#tree-classification)
    *   [1.10.2\. 回归](modules/tree.html#tree-regression)
    *   [1.10.3\. 多值输出问题](modules/tree.html#tree-multioutput)
    *   [1.10.4\. 复杂度分析](modules/tree.html#tree-complexity)
    *   [1.10.5\. 实际使用技巧](modules/tree.html#id6)
    *   [1.10.6\. 决策树算法: ID3, C4.5, C5.0 和 CART](modules/tree.html#tree-algorithms)
    *   [1.10.7\. 数学表达](modules/tree.html#tree-mathematical-formulation)
        *   [1.10.7.1\. 分类标准](modules/tree.html#id9)
        *   [1.10.7.2\. 回归标准](modules/tree.html#id10)
*   [1.11\. 集成方法](modules/ensemble.html)
    *   [1.11.1\. Bagging meta-estimator（Bagging 元估计器）](modules/ensemble.html#bagging-meta-estimator-bagging)
    *   [1.11.2\. 由随机树组成的森林](modules/ensemble.html#forest)
        *   [1.11.2.1\. 随机森林](modules/ensemble.html#id8)
        *   [1.11.2.2\. 极限随机树](modules/ensemble.html#id10)
        *   [1.11.2.3\. 参数](modules/ensemble.html#id11)
        *   [1.11.2.4\. 并行化](modules/ensemble.html#id12)
        *   [1.11.2.5\. 特征重要性评估](modules/ensemble.html#random-forest-feature-importance)
        *   [1.11.2.6\. 完全随机树嵌入](modules/ensemble.html#random-trees-embedding)
    *   [1.11.3\. AdaBoost](modules/ensemble.html#adaboost)
        *   [1.11.3.1\. 使用方法](modules/ensemble.html#id20)
    *   [1.11.4\. Gradient Tree Boosting（梯度树提升）](modules/ensemble.html#gradient-tree-boosting)
        *   [1.11.4.1\. 分类](modules/ensemble.html#id22)
        *   [1.11.4.2\. 回归](modules/ensemble.html#id23)
        *   [1.11.4.3\. 训练额外的弱学习器](modules/ensemble.html#gradient-boosting-warm-start)
        *   [1.11.4.4\. 控制树的大小](modules/ensemble.html#gradient-boosting-tree-size)
        *   [1.11.4.5\. Mathematical formulation（数学公式）](modules/ensemble.html#mathematical-formulation)
            *   [1.11.4.5.1\. Loss Functions（损失函数）](modules/ensemble.html#loss-functions)
        *   [1.11.4.6\. Regularization（正则化）](modules/ensemble.html#regularization)
            *   [1.11.4.6.1\. 收缩率 (Shrinkage)](modules/ensemble.html#shrinkage)
            *   [1.11.4.6.2\. 子采样 (Subsampling)](modules/ensemble.html#subsampling)
        *   [1.11.4.7\. Interpretation（解释性）](modules/ensemble.html#interpretation)
            *   [1.11.4.7.1\. Feature importance（特征重要性）](modules/ensemble.html#feature-importance)
            *   [1.11.4.7.2\. Partial dependence（部分依赖）](modules/ensemble.html#partial-dependence)
    *   [1.11.5\. Voting Classifier（投票分类器）](modules/ensemble.html#voting-classifier)
        *   [1.11.5.1\. 多数类标签 (又称为 多数/硬投票)](modules/ensemble.html#id38)
            *   [1.11.5.1.1\. 用法](modules/ensemble.html#id39)
        *   [1.11.5.2\. 加权平均概率 （软投票）](modules/ensemble.html#id40)
        *   [1.11.5.3\. 投票分类器（VotingClassifier）在网格搜索（GridSearch）应用](modules/ensemble.html#votingclassifier-gridsearch)
            *   [1.11.5.3.1\. 用法](modules/ensemble.html#id41)
*   [1.12\. 多类和多标签算法](modules/multiclass.html)
    *   [1.12.1\. 多标签分类格式](modules/multiclass.html#id4)
    *   [1.12.2\. 1对其余](modules/multiclass.html#ovr-classification)
        *   [1.12.2.1\. 多类学习](modules/multiclass.html#id6)
        *   [1.12.2.2\. 多标签学习](modules/multiclass.html#id7)
    *   [1.12.3\. 1对1](modules/multiclass.html#ovo-classification)
        *   [1.12.3.1\. 多类别学习](modules/multiclass.html#id9)
    *   [1.12.4\. 误差校正输出代码](modules/multiclass.html#ecoc)
        *   [1.12.4.1\. 多类别学习](modules/multiclass.html#id12)
    *   [1.12.5\. 多输出回归](modules/multiclass.html#id14)
    *   [1.12.6\. 多输出分类](modules/multiclass.html#id15)
    *   [1.12.7\. 链式分类器](modules/multiclass.html#id16)
*   [1.13\. 特征选择](modules/feature_selection.html)
    *   [1.13.1\. 移除低方差特征](modules/feature_selection.html#variance-threshold)
    *   [1.13.2\. 单变量特征选择](modules/feature_selection.html#univariate-feature-selection)
    *   [1.13.3\. 递归式特征消除](modules/feature_selection.html#rfe)
    *   [1.13.4\. 使用 SelectFromModel 选取特征](modules/feature_selection.html#selectfrommodel)
        *   [1.13.4.1\. 基于 L1 的特征选取](modules/feature_selection.html#l1)
        *   [1.13.4.2\. 基于 Tree（树）的特征选取](modules/feature_selection.html#tree)
    *   [1.13.5\. 特征选取作为 pipeline（管道）的一部分](modules/feature_selection.html#pipeline)
*   [1.14\. 半监督学习](modules/label_propagation.html)
    *   [1.14.1\. 标签传播](modules/label_propagation.html#label-propagation)
*   [1.15\. 等式回归](modules/isotonic.html)
*   [1.16\. 概率校准](modules/calibration.html)
*   [1.17\. 神经网络模型（有监督）](modules/neural_networks_supervised.html)
    *   [1.17.1\. 多层感知器](modules/neural_networks_supervised.html#multilayer-perceptron)
    *   [1.17.2\. 分类](modules/neural_networks_supervised.html#id3)
    *   [1.17.3\. 回归](modules/neural_networks_supervised.html#id4)
    *   [1.17.4\. 正则化](modules/neural_networks_supervised.html#id5)
    *   [1.17.5\. 算法](modules/neural_networks_supervised.html#id6)
    *   [1.17.6\. 复杂度](modules/neural_networks_supervised.html#id7)
    *   [1.17.7\. 数学公式](modules/neural_networks_supervised.html#id8)
    *   [1.17.8\. 实用技巧](modules/neural_networks_supervised.html#mlp-tips)
    *   [1.17.9\. 使用 warm_start 的更多控制](modules/neural_networks_supervised.html#warm-start)